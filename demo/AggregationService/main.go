package main

import (
	// "context"
	"bufio"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"strings"
	"bytes"
	"gopkg.in/avro.v0"
)

// AggregatableReport contains the information generated by the Attribution
// Reporting API in the browser
type AggregatableReport struct {
	SourceSite             string `json:"source_site"`
	AttributionDestination string `json:"attribution_destination"`
	// SharedInfo is a JSON serialized instance of struct SharedInfo.
	// This exact string is used as authenticated data for decryption. The string
	// therefore must be forwarded to the aggregation service unmodified. The
	// reporting origin can parse the string to access the encoded fields.
	// https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md#aggregatable-reports
	SharedInfo                 string                       `json:"shared_info"`
	AggregationServicePayloads []*AggregationServicePayload `json:"aggregation_service_payloads"`

	SourceDebugKey  uint64 `json:"source_debug_key,string"`
	TriggerDebugKey uint64 `json:"trigger_debug_key,string"`
}

// AggregationServicePayload contains the payload for the aggregation server.
type AggregationServicePayload struct {
	// Payload is a encrypted CBOR serialized instance of struct Payload, which is base64 encoded.
	Payload               string `json:"payload"`
	KeyID                 string `json:"key_id"`
	DebugCleartextPayload string `json:"debug_cleartext_payload,omitempty"`
}

// AvroAggregatableReport format expected by aggregation service and local testing tool
type AvroAggregatableReport struct {
	Payload    []byte `avro:"payload"`
	KeyID      string `avro:"key_id"`
	SharedInfo string `avro:"shared_info"`
}

func check(e error) {
	if e != nil {
		panic(e)
	}
}

const endpoint = "debug"
var schema, _ = avro.ParseSchemaFile("report.avsc")
var f, _ = os.Create(fmt.Sprintf("data/output_%s_reports.avro", endpoint))
var w = bufio.NewWriter(f)
var writer, _ = avro.NewDataFileWriter(w, schema, avro.NewSpecificDatumWriter())
var df, _ = os.Create(fmt.Sprintf("data/output_%s_clear_text_reports.avro", endpoint))
var dw = bufio.NewWriter(df)
var dwriter, _ = avro.NewDataFileWriter(dw, schema, avro.NewSpecificDatumWriter())

func collectEndpoint(input string) {

	report := &AggregatableReport{}
	if err := json.Unmarshal([]byte(input), report); err != nil {
		errMsg := "Failed in decoding aggregation report"
		log.Printf(errMsg+" %v", err)
		return
	}

	for _, payload := range report.AggregationServicePayloads {
		var payload_cbor []byte
		var err error

		payload_cbor, err = base64.StdEncoding.DecodeString(payload.Payload)

		check(err)
		avroReport := &AvroAggregatableReport{
			Payload:    []byte(string(payload_cbor)),
			KeyID:      payload.KeyID,
			SharedInfo: report.SharedInfo,
		}

		if err := writer.Write(avroReport); err != nil {
			log.Fatal(err) // i/o errors OR encoding errors
		}

		if len(payload.DebugCleartextPayload) > 0 {
			payload_debug_cbor, err := base64.StdEncoding.DecodeString(payload.DebugCleartextPayload)
			check(err)
			avroDReport := &AvroAggregatableReport{
				Payload:    []byte(string(payload_debug_cbor)),
				KeyID:      payload.KeyID,
				SharedInfo: report.SharedInfo,
			}
			if err := dwriter.Write(avroDReport); err != nil {
				log.Fatal(err) // i/o errors OR encoding errors
			}
		}
	}
	writer.Flush()
	w.Flush()
	if dwriter != nil {
		dwriter.Flush()
		dw.Flush()
	}
}

func splitJSONObjects(content string) []string {
	var objects []string
	var buffer bytes.Buffer
	openBraces := 0

	for _, char := range content {
		switch char {
		case '{':
			if openBraces == 0 && buffer.Len() > 0 {
				objects = append(objects, buffer.String())
				buffer.Reset()
			}
			openBraces++
		case '}':
			openBraces--
		}

		buffer.WriteRune(char)

		if openBraces == 0 && buffer.Len() > 0 {
			objects = append(objects, buffer.String())
			buffer.Reset()
		}
	}

	return objects
}


func main() {

	file, err := os.Open("../functions/apps/QueryReport.txt")
	if err != nil {
		fmt.Println("Error opening file:", err)
		return
	}

	var fileContent strings.Builder
	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		fileContent.WriteString(scanner.Text())
	}

	if err := scanner.Err(); err != nil {
		fmt.Println("Error reading file:", err)
		return
	}

	content := fileContent.String()
	jsonObjects := splitJSONObjects(content)

	for _, jsonObject := range jsonObjects {

		collectEndpoint(jsonObject)
	}


	defer file.Close()
	defer f.Close()
	defer df.Close()


}
